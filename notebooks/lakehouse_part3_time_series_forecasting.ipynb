{"cells": [{"cell_type": "code", "id": "lvNpj26L7bbY67xWsvugZull", "metadata": {"tags": [], "id": "lvNpj26L7bbY67xWsvugZull", "executionInfo": {"status": "ok", "timestamp": 1752764071452, "user_tz": -120, "elapsed": 5, "user": {"displayName": "", "userId": ""}}}, "source": ["# Copyright 2025 Google LLC\n", "#\n", "# Licensed under the Apache License, Version 2.0 (the \"License\");\n", "# you may not use this file except in compliance with the License.\n", "# You may obtain a copy of the License at\n", "#\n", "#     https://www.apache.org/licenses/LICENSE-2.0\n", "#\n", "# Unless required by applicable law or agreed to in writing, software\n", "# distributed under the License is distributed on an \"AS IS\" BASIS,\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n", "# See the License for the specific language governing permissions and\n", "# limitations under the License."], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["# Ridership Open Lakehouse Demo (Part 3): Time-Series forecasting of ridership data\n", "\n", "This notebook will demonstrate a strategy to implement an open lakehouse on GCP, using Apache Iceberg, as an open source standard for managing data, while still leveraging GCP native capabilities. This demo will use BigQuery Manged Iceberg Tables, Managed Apache Kafka and Apache Kafka Connect to ingest streaming data, Vertex AI for Generative AI queries on top of the data and Dataplex to govern tables.\n", "\n", "This notebook will use the `bus_rides` data and ML models to generate a time-series forcasting of ridership in the future, in order to alert us when a bus about to become full.\n", "\n", "We will evaluate the models accuracy and generate future data to be used in the next chapters for real-time predictions and alerting."], "metadata": {"id": "g4xlhet9alul"}, "id": "g4xlhet9alul", "execution_count": null}, {"cell_type": "markdown", "source": ["## Setup the environment"], "metadata": {"id": "TJNbPGBEgQKC"}, "id": "TJNbPGBEgQKC", "execution_count": null}, {"cell_type": "code", "source": ["import os\n", "USER_AGENT = \"cloud-solutions/data-to-ai-nb-v3\"\n", "\n", "PROJECT_ID = !gcloud config get-value project\n", "PROJECT_ID = PROJECT_ID[0]\n", "BQ_DATASET = \"ridership_lakehouse\"\n", "BUCKET_NAME = f\"{PROJECT_ID}-ridership-lakehouse\"\n", "LOCATION = \"us-central1\"\n", "BQ_CONNECTION_NAME = \"cloud-resources-connection\"\n", "\n", "\n", "print(PROJECT_ID)\n", "print(BUCKET_NAME)"], "metadata": {"id": "UbBMzAcsgaOW", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1752764075093, "user_tz": -120, "elapsed": 1980, "user": {"displayName": "", "userId": ""}}, "outputId": "19b14547-b29c-4199-e19f-874092911c84"}, "id": "UbBMzAcsgaOW", "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from google.cloud import bigquery, storage\n", "from google.api_core.client_info import ClientInfo\n", "\n", "bigquery_client = bigquery.Client(\n", "    project=PROJECT_ID,\n", "    location=LOCATION,\n", "    client_info=ClientInfo(user_agent=USER_AGENT)\n", ")\n", "storage_client = storage.Client(\n", "    project=PROJECT_ID,\n", "    client_info=ClientInfo(user_agent=USER_AGENT)\n", ")"], "metadata": {"id": "NXsTs1pda7rF", "executionInfo": {"status": "ok", "timestamp": 1752764083211, "user_tz": -120, "elapsed": 4791, "user": {"displayName": "", "userId": ""}}}, "id": "NXsTs1pda7rF", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["# Feature Engineering\n", "\n", "Let's assume that bus ridership depends on a number of factors:\n", "  * Station\n", "  * Bus line\n", "  * The Date and Time (time series)\n", "  \n", "  We will use the data generated in notebooks 1 & 2 to forecast ridership, based on these factors.\n", "\n", "  Obviously, some of these variable are related (the station and Borough are realted). In a real-world scenario, this might be a bad practice, and might lead to overfitting towards a specific variable, but for the sake of the demo we will try to use these features."], "metadata": {"id": "4ZeA3dCQPpVE"}, "id": "4ZeA3dCQPpVE", "execution_count": null}, {"cell_type": "markdown", "source": ["### Create ridership table"], "metadata": {"id": "OeEJB9VBT7-m"}, "id": "OeEJB9VBT7-m", "execution_count": null}, {"cell_type": "code", "source": ["table_name = \"bus_rides_features\"\n", "\n", "ridership_features_uri = f\"gs://{BUCKET_NAME}/iceberg_data/{table_name}/\"\n", "\n", "bigquery_client.query(f\"DROP TABLE IF EXISTS {BQ_DATASET}.{table_name};\").result()\n", "query = f\"\"\"\n", "CREATE TABLE `{BQ_DATASET}.{table_name}`\n", "WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{BQ_CONNECTION_NAME}`\n", "OPTIONS (\n", "  file_format = 'PARQUET',\n", "  table_format = 'ICEBERG',\n", "  storage_uri = '{ridership_features_uri}'\n", ")\n", "AS\n", "(\n", "  SELECT\n", "  r.timestamp_at_stop,\n", "  r.bus_ride_id,\n", "  r.bus_stop_id,\n", "  r.bus_line_id,\n", "  r.bus_size,\n", "  r.total_capacity,\n", "  s.borough,\n", "  r.passengers_in_stop,\n", "  r.passengers_boarding,\n", "  r.passengers_alighting,\n", "  r.remaining_capacity,\n", "  r.remaining_at_stop,\n", "  COALESCE(SAFE_DIVIDE(r.remaining_capacity, r.total_capacity), 0) AS remaining_capacity_percentage,\n", "  COALESCE(SAFE_DIVIDE(r.remaining_at_stop, r.passengers_in_stop), 0) AS passengers_left_behind_percentage\n", "FROM `{BQ_DATASET}.bus_rides` AS r\n", "LEFT JOIN `{BQ_DATASET}.bus_stations` AS s ON s.bus_stop_id = r.bus_stop_id\n", ");\n", "\"\"\"\n", "bigquery_client.query(query).result()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "zYO9_4gfJLXB", "executionInfo": {"status": "ok", "timestamp": 1752767562327, "user_tz": -120, "elapsed": 4976, "user": {"displayName": "", "userId": ""}}, "outputId": "475bb837-e171-444b-965a-920add573039"}, "id": "zYO9_4gfJLXB", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["## Visualize Projected data\n", "\n", "Let's now create a visualization for each of these features, the relationship with the `ridership` column, to see the effects of different features on the target variable."], "metadata": {"id": "3yMyeDdVUXHY"}, "id": "3yMyeDdVUXHY", "execution_count": null}, {"cell_type": "markdown", "source": ["### ridership per station over time\n", "Let's take a look at the last 90 days of generated data. The first bus stop graph also shows the temperature and percipitation values."], "metadata": {"id": "ue5rOAnkJ_IE"}, "id": "ue5rOAnkJ_IE", "execution_count": null}, {"cell_type": "code", "source": ["import matplotlib.pyplot as plt\n", "import pandas as pd\n", "import random\n", "\n", "ridership_history = bigquery_client.query(f\"\"\"\n", "DECLARE max_ts TIMESTAMP DEFAULT (SELECT MAX(timestamp_at_stop) FROM ridership_lakehouse.{table_name});\n", "SELECT *\n", "  FROM `ridership_lakehouse.{table_name}`\n", "  WHERE timestamp_at_stop > TIMESTAMP_SUB(max_ts, INTERVAL 90 DAY)\n", "\"\"\").result().to_dataframe()\n", "\n", "random.seed(42)\n", "\n", "# we'll sample 20 random stations, as displaying all of them is not practical\n", "bus_line_ids = random.sample(list(ridership_history.bus_line_id.unique()), k=20)\n", "\n", "figure = plt.figure(figsize=(20, 6))\n", "plt.xlabel('Timestamp at stop')\n", "# Group data by station ID\n", "for bus_line_id in bus_line_ids:\n", "  station_data = ridership_history[ridership_history['bus_line_id'] == bus_line_id].sort_values(by=\"timestamp_at_stop\")\n", "  # Plot ridership over time for the current station\n", "  plt.plot(station_data['timestamp_at_stop'], station_data['remaining_at_stop'], label=f'Bus Line {bus_line_id}')\n", "\n", "# Customize the plot\n", "plt.xlabel('Timestamp at stop')\n", "plt.ylabel('Remaining Passengers')\n", "plt.title('Remaining Passengers Over Time by Bus Line')\n", "plt.legend()\n", "plt.xticks(rotation=45)\n", "plt.tight_layout()\n", "plt.show()"], "metadata": {"id": "GWVIBjf8Z2pK", "colab": {"base_uri": "https://localhost:8080/", "height": 366}, "executionInfo": {"status": "ok", "timestamp": 1752767571847, "user_tz": -120, "elapsed": 5171, "user": {"displayName": "", "userId": ""}}, "outputId": "93270339-f8da-49a8-965c-a4ad27241219"}, "id": "GWVIBjf8Z2pK", "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["del ridership_history  # save on ram space"], "metadata": {"id": "Q9s5TmPjdzKx"}, "id": "Q9s5TmPjdzKx", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### Avg ridership per Borough"], "metadata": {"id": "tG9QTLedfSnT"}, "id": "tG9QTLedfSnT", "execution_count": null}, {"cell_type": "code", "source": ["average_ridership_per_borough = bigquery_client.query(\"\"\"\n", "-- select a random sample of data, group by `borough` and calculate the average of ridership\n", "SELECT\n", "  borough,\n", "  AVG(ridership) AS average_ridership\n", "FROM\n", "  `ridership_lakehouse`.`ridership_features`\n", "TABLESAMPLE\n", "  SYSTEM(10 PERCENT)\n", "GROUP BY\n", "  borough;\n", "\"\"\").result().to_dataframe()\n", "\n", "# Sort by average ridership to ensure correct order in the plot\n", "average_ridership_per_borough = average_ridership_per_borough.sort_values(by='average_ridership').reset_index()\n", "\n", "average_ridership_per_borough.plot.bar(y='average_ridership', x='borough', rot=0)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 466}, "id": "ld9h94TofKOZ", "executionInfo": {"status": "ok", "timestamp": 1750684288015, "user_tz": -120, "elapsed": 2309, "user": {"displayName": "", "userId": ""}}, "outputId": "5d580042-a9fc-437c-aa85-c91daffdd533"}, "id": "ld9h94TofKOZ", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### Average ridership per month"], "metadata": {"id": "SFph12cCmibo"}, "id": "SFph12cCmibo", "execution_count": null}, {"cell_type": "code", "source": ["# Generate New Visualization: Average Ridership per Month -- we'll select a new preojection\n", "\n", "# Calculate average ridership per month\n", "# Group by 'transit_month' and calculate the mean of 'ridership'\n", "average_ridership_per_month = bigquery_client.query(\"\"\"\n", "-- select a random sample of data, group by `transit_month` and calculate the average of ridership\n", "SELECT\n", "  transit_month,\n", "  AVG(ridership) AS average_ridership\n", "FROM\n", "  `ridership_lakehouse`.`ridership_features`\n", "TABLESAMPLE\n", "  SYSTEM(10 PERCENT)\n", "GROUP BY\n", "  transit_month;\n", "\"\"\").result().to_dataframe()\n", "\n", "# Sort by month to ensure correct chronological order in the plot\n", "average_ridership_per_month = average_ridership_per_month.sort_values(by='transit_month').reset_index()\n", "\n", "plt.figure(figsize=(10, 6)) # Adjust figure size\n", "\n", "plt.plot(average_ridership_per_month['transit_month'], average_ridership_per_month['average_ridership'], marker='o', linestyle='-', color='skyblue')\n", "\n", "# Add plot labels and title\n", "plt.xlabel(\"Transit Month\")\n", "plt.ylabel(\"Average Ridership\")\n", "plt.title(\"Average Transit Minutly Ridership per Month\")\n", "plt.xticks(average_ridership_per_month['transit_month']) # Ensure all months are shown on x-axis\n", "plt.grid(True, linestyle='--', alpha=0.6)\n", "plt.tight_layout()\n", "plt.show()\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 607}, "id": "G-5DC96y03uE", "executionInfo": {"status": "ok", "timestamp": 1750684290047, "user_tz": -120, "elapsed": 2035, "user": {"displayName": "", "userId": ""}}, "outputId": "6ed4cd1f-840c-45e6-f7a4-f5ab79b33eff"}, "id": "G-5DC96y03uE", "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["del average_ridership_per_month  # save on RAM"], "metadata": {"id": "IZ2grPARd4Sk"}, "id": "IZ2grPARd4Sk", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### Average Ridership per Day-of-Week"], "metadata": {"id": "siu6JTn9mrQK"}, "id": "siu6JTn9mrQK", "execution_count": null}, {"cell_type": "code", "source": ["# Generate New Visualization: Average Ridership per Day-of-Week\n", "\n", "# Calculate average ridership per day of week\n", "# Group by 'transit_day_of_week' and calculate the mean of 'ridership'\n", "average_ridership_per_day_of_week = bigquery_client.query(\"\"\"\n", "-- select a random sample of data, group by `transit_day_of_week` and calculate the average of ridership\n", "SELECT\n", "  transit_day_of_week,\n", "  AVG(ridership) AS average_ridership\n", "FROM\n", "  `ridership_lakehouse`.`ridership_features`\n", "TABLESAMPLE\n", "  SYSTEM(10 PERCENT)\n", "GROUP BY\n", "  transit_day_of_week;\n", "\"\"\").result().to_dataframe()\n", "\n", "# Sort by month to ensure correct chronological order in the plot\n", "average_ridership_per_day_of_week = average_ridership_per_day_of_week.sort_values(by='transit_day_of_week').reset_index()\n", "\n", "days_of_week = {\n", "    1: \"Sunday\",\n", "    2: \"Monday\",\n", "    3: \"Tuesday\",\n", "    4: \"Wednesday\",\n", "    5: \"Thursday\",\n", "    6: \"Friday\",\n", "    7: \"Saturday\"\n", "}\n", "average_ridership_per_day_of_week['transit_day_of_week'] = average_ridership_per_day_of_week['transit_day_of_week'].map(days_of_week)\n", "plt.figure(figsize=(10, 6)) # Adjust figure size\n", "\n", "plt.plot(average_ridership_per_day_of_week['transit_day_of_week'], average_ridership_per_day_of_week['average_ridership'], marker='o', linestyle='-', color='skyblue')\n", "\n", "# Add plot labels and title\n", "plt.xlabel(\"Transit Day of Week\")\n", "plt.ylabel(\"Average Ridership\")\n", "plt.title(\"Average Transit Minutly Ridership per Day of Week\")\n", "plt.xticks(average_ridership_per_day_of_week['transit_day_of_week']) # Ensure all months are shown on x-axis\n", "plt.grid(True, linestyle='--', alpha=0.6)\n", "plt.tight_layout()\n", "plt.show()\n"], "metadata": {"id": "FBbFMM971nYk", "colab": {"base_uri": "https://localhost:8080/", "height": 607}, "executionInfo": {"status": "ok", "timestamp": 1750684322030, "user_tz": -120, "elapsed": 2691, "user": {"displayName": "", "userId": ""}}, "outputId": "2681c217-e980-4089-8c30-039918900870"}, "id": "FBbFMM971nYk", "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["del average_ridership_per_day_of_week  # save on RAM"], "metadata": {"id": "k5DIqJsXnS5v"}, "id": "k5DIqJsXnS5v", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["# Forecast bus ridership\n", "\n", "For time-series forecasting, there are 3 main options to choose from.\n", "\n", "### ARIMA_PLUS\n", "This model is an enhanced version of the traditional ARIMA, offering improved performance and often including automatic parameter selection for better ease of use in forecasting univariate time series. It's a **Univariate** model, meaning, it is built to predict a target value based on only the timestamp variable. You cannot incorportate extra variables that might influence the prediction. For that reason, we will **NOT** use it here in our demo.\n", "\n", "### ARIMA_PLUS_XREG\n", "Extending `ARIMA_PLUS`, this model incorporates the ability to utilize external regressors (exogenous variables) to enhance the forecasting accuracy by accounting for the influence of other relevant time series. Like the `ARIMA_P{LUS` It still relies on linearity assumptions between regressors and target. It is a Multivariate model, in terms of inputs, but still forecasts a single output.)\n", "\n", "### TimesFM\n", "`TimesFM` is a deep learning-based forecasting model that leverages transformer architectures to capture complex temporal dependencies and long-range patterns in time series data, often excelling in multi-variate forecasting tasks. It's considered excellent at capturing complex non-linear patterns and long-range dependencies; naturally handles multivariate inputs and outputs; can perform well with large datasets.It can be, however, prone to overfitting with small datasets.\n", "\n", "## What's next?\n", "\n", "In the rest of this notebook, we will create predication using both `ARIMA_PLUS_XREG` and `TimesFM` and evaluate each, so we can comopare the performance of each of the models.\n"], "metadata": {"id": "hfMnFM06jIyJ"}, "id": "hfMnFM06jIyJ", "execution_count": null}, {"cell_type": "markdown", "source": ["## Multivariate forecasting using the ARIMA_PLUS_XREG model"], "metadata": {"id": "6F7BaDwQaECx"}, "id": "6F7BaDwQaECx", "execution_count": null}, {"cell_type": "markdown", "source": ["### Train the model\n", "\n", "\n", "The same CREATE MODEL statement is used to train this model Many options, e.g,  `time_series_data_col`, `time_series_timestamp_col`,  `time_series_id_col` have the same meaning as for the ARIMA_PLUS model.\n", "\n", "The main difference - the ARIMA_PLUS_XREG model uses all columns besides those identified by the options above as the feature columns and uses linear regression to calculate covariate weights.\n", "\n", "For details on the additional options, explanation of the training process, and best practices when training and using the model please refer to BigQuery documentation on [the CREATE MODEL statement for ARIMA_PLUS_XREG models](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-multivariate-time-series)."], "metadata": {"id": "yzogKPO25C0H"}, "id": "yzogKPO25C0H", "execution_count": null}, {"cell_type": "code", "source": ["%%bigquery\n", "DECLARE min_ts TIMESTAMP DEFAULT TIMESTAMP(\"2023-09-01T00:00:00\");\n", "DECLARE max_ts TIMESTAMP DEFAULT TIMESTAMP(\"2024-08-31T23:59:59\");\n", "\n", "CREATE OR REPLACE MODEL `ridership_lakehouse.ridership_arima_plus_xreg`\n", "OPTIONS(\n", "  MODEL_TYPE = 'ARIMA_PLUS_XREG',\n", "  TIME_SERIES_ID_COL = ['station_id'],\n", "  TIME_SERIES_DATA_COL = 'ridership',\n", "  TIME_SERIES_TIMESTAMP_COL = 'transit_timestamp',\n", "  AUTO_ARIMA=TRUE,\n", "  -- DATA_FREQUENCY='MONTHLY',\n", "  HOLIDAY_REGION = \"US\"  -- the original dataset is from NY\n", ")\n", "AS SELECT\n", "  station_id,\n", "  borough,\n", "  transit_month,\n", "  transit_day_of_week,\n", "  transit_timestamp,\n", "  ridership\n", "FROM `ridership_lakehouse.ridership_features`\n", "TABLESAMPLE\n", "  SYSTEM(70 PERCENT)\n", "WHERE transit_timestamp >= min_ts AND transit_timestamp < max_ts; -- we're only training"], "metadata": {"id": "xM1y3GXljNwn", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1750684893346, "user_tz": -120, "elapsed": 201816, "user": {"displayName": "", "userId": ""}}, "outputId": "e504ea8e-6d7e-4e2a-b59a-30c7ca2f612c"}, "id": "xM1y3GXljNwn", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### Forecast ridership"], "metadata": {"id": "O4g_N5GukpKD"}, "id": "O4g_N5GukpKD", "execution_count": null}, {"cell_type": "markdown", "source": [], "metadata": {"id": "R279u7DGKVXs"}, "id": "R279u7DGKVXs", "execution_count": null}, {"cell_type": "markdown", "source": ["Let's move the latest forecast data to the location of the model:"], "metadata": {"id": "0mFPcZuA0FnK"}, "id": "0mFPcZuA0FnK", "execution_count": null}, {"cell_type": "code", "source": ["%%bigquery --project {PROJECT_ID}\n", "\n", "DROP TABLE IF EXISTS multimodal.latest_local_forecast;"], "metadata": {"id": "-8L08fxQK9Rk"}, "id": "-8L08fxQK9Rk", "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["! bq cp -f -n '{PROJECT_ID}:weathernext_graph_derived.latest_local_forecast' '{PROJECT_ID}:multimodal.latest_local_forecast'"], "metadata": {"id": "yGb6uc-B06-b"}, "id": "yGb6uc-B06-b", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["#### Run the time-series forecast"], "metadata": {"id": "RhQ_QkGxNjbg"}, "id": "RhQ_QkGxNjbg", "execution_count": null}, {"cell_type": "markdown", "source": ["If we were to use the ARIMA_PLUS model we could have just run the ML.FORECAST function to get time-series predictions. But the ARIMA_PLUS_XREG assumes that additional features will affect the forecast and you must provide the expected features to the ML.FORECAST function.\n", "\n", "We already have most of the parts to prepare the features. Let's first test the feature preparation SQL before running the model.\n", "\n"], "metadata": {"id": "VeOl0UzUHWve"}, "id": "VeOl0UzUHWve", "execution_count": null}, {"cell_type": "code", "source": ["%%bigquery expected_features --project {PROJECT_ID}\n", "\n", "DECLARE time_zone DEFAULT \"America/New_York\";\n", "\n", "-- Forecast from now...\n", "DECLARE start_ts DEFAULT CURRENT_TIMESTAMP();\n", "-- to 5 days forward\n", "DECLARE end_ts DEFAULT TIMESTAMP_ADD(start_ts, INTERVAL 5 DAY);\n", "\n", "WITH\n", "event_timestamps AS (\n", "  SELECT TIMESTAMP(DATETIME(event_ts_in_utc, time_zone)) event_ts FROM\n", "    UNNEST(GENERATE_TIMESTAMP_ARRAY(start_ts, end_ts, INTERVAL 5 MINUTE)) as event_ts_in_utc\n", "),\n", "bus_stops_and_event_timestamps AS (\n", "  -- Cartesian join of the bus stops and time points\n", "  -- We only need the bus stop ids and locations, not all the meta data\n", "  SELECT bus_stops.bus_stop_id, bus_stops.location, event_ts\n", "    FROM multimodal.bus_stops, event_timestamps\n", "),\n", "events_and_weather AS (\n", "  SELECT\n", "    bus_stop_id,\n", "    event_ts,\n", "    weather.forecast,\n", "    multimodal.temperature_approx(weather.forecast, event_ts) as temperature,\n", "    -- we are getting the latest forecast data, not historical\n", "    FROM bus_stops_and_event_timestamps events, multimodal.latest_local_forecast weather\n", "      WHERE ST_COVERS(weather.geography_polygon, events.location) AND\n", "        event_ts BETWEEN TIMESTAMP_SUB(weather.forecast.time, INTERVAL 6 HOUR) AND weather.forecast.time\n", ")\n", "SELECT\n", "    bus_stop_id,\n", "    event_ts,\n", "    -- the two features used by the model\n", "    temperature,\n", "    forecast.total_precipitation_6hr as total_precipitation_6hr,\n", "    FROM events_and_weather\n", "    -- we are going to drop these clauses later, this is just to help with visualization\n", "    ORDER by bus_stop_id, event_ts\n", "    LIMIT 50;"], "metadata": {"id": "ekoHAClRID0o"}, "id": "ekoHAClRID0o", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Let's see what these features look like:"], "metadata": {"id": "Z4pdlEhjJDxr"}, "id": "Z4pdlEhjJDxr", "execution_count": null}, {"cell_type": "code", "source": ["display(expected_features)"], "metadata": {"id": "_lsEtN5VJIYt"}, "id": "_lsEtN5VJIYt", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["OK, the features look correct. One nuance - you might see that the temperature values are unchanged for some earlier event timestamps. This is because our latest forecast table doesn't have temperature values for earlier forecasts and the temperature approximation function just takes the current value if there is no earlier one. We can find this data if needed by looking at the previous forecast, but that would result in more complex SQL statement.\n", "\n", "Let's run the forecast. We will use most of the feature preparation SQL in the forecasting function. Alternatively, we could have prepared the features and saved them in a table and used the whole table as the feature input to the forecast function."], "metadata": {"id": "qjNikfTFJvK-"}, "id": "qjNikfTFJvK-", "execution_count": null}, {"cell_type": "code", "source": ["%%bigquery ridership_forecast --location {REGION}\n", "\n", "DECLARE time_zone DEFAULT \"America/New_York\";\n", "\n", "-- Forecast from now...\n", "DECLARE start_ts DEFAULT CURRENT_TIMESTAMP();\n", "-- to 5 days forward\n", "DECLARE end_ts DEFAULT TIMESTAMP_ADD(start_ts, INTERVAL 5 DAY);\n", "\n", "SELECT\n", "  *\n", "FROM\n", "  ML.FORECAST (\n", "    model `multimodal.ridership_arima_plus_xreg`,\n", "    STRUCT (1000 AS horizon, 0.8 AS confidence_level),\n", "    (\n", "WITH\n", "event_timestamps AS (\n", "  SELECT TIMESTAMP(DATETIME(event_ts_in_utc, time_zone)) event_ts FROM\n", "    UNNEST(GENERATE_TIMESTAMP_ARRAY(start_ts, end_ts, INTERVAL 5 MINUTE)) as event_ts_in_utc\n", "),\n", "bus_stops_and_event_timestamps AS (\n", "  -- Cartesian join of the bus stops and time points\n", "  -- We only need the bus stop ids and locations, not all the meta data\n", "  SELECT bus_stops.bus_stop_id, bus_stops.location, event_ts FROM multimodal.bus_stops, event_timestamps\n", "),\n", "events_and_weather AS (\n", "  SELECT\n", "    bus_stop_id,\n", "    event_ts,\n", "    weather.forecast,\n", "    multimodal.temperature_approx(weather.forecast, event_ts) as temperature,\n", "    -- we are getting the latest forecast data, not historical\n", "    FROM bus_stops_and_event_timestamps events, multimodal.latest_local_forecast weather\n", "      WHERE ST_COVERS(weather.geography_polygon, events.location) AND\n", "        event_ts BETWEEN TIMESTAMP_SUB( weather.forecast.time, INTERVAL 6 HOUR) AND weather.forecast.time\n", ")\n", "SELECT\n", "    bus_stop_id,\n", "    event_ts,\n", "    -- the two features used by the model\n", "    temperature,\n", "    forecast.total_precipitation_6hr as total_precipitation_6hr,\n", "    FROM events_and_weather    )\n", "  );"], "metadata": {"id": "KcS2GPMqktw5"}, "id": "KcS2GPMqktw5", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["#### Visualize the forecast"], "metadata": {"id": "Qjh7K1_HlXwr"}, "id": "Qjh7K1_HlXwr", "execution_count": null}, {"cell_type": "markdown", "source": ["Here's what the ML.FORECAST function returns:"], "metadata": {"id": "1vPfTPSuVQnW"}, "id": "1vPfTPSuVQnW", "execution_count": null}, {"cell_type": "code", "source": ["display(ridership_forecast)"], "metadata": {"id": "Bix0T7drJF_E"}, "id": "Bix0T7drJF_E", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Let's visualize the forecast:"], "metadata": {"id": "tleV9kMlVjKU"}, "id": "tleV9kMlVjKU", "execution_count": null}, {"cell_type": "code", "source": ["\n", "bus_stop_list = list(ridership_history.bus_stop_id.unique())\n", "bus_stop_list.sort()\n", "\n", "for bus_stop_id in bus_stop_list:\n", "\n", "    historical_data = ridership_history[ridership_history.bus_stop_id==bus_stop_id]\n", "    forecast_data = ridership_forecast[ridership_forecast.bus_stop_id==bus_stop_id]\n", "    plot_historical_and_forecast(historical_data = historical_data,\n", "                                 timestamp_col_name = \"event_ts\",\n", "                                 data_col_name = \"num_riders\",\n", "                                 forecast_output = forecast_data,\n", "                                 title = bus_stop_id)"], "metadata": {"id": "MI2t8RfHlbpT"}, "id": "MI2t8RfHlbpT", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["# Selecting the right model"], "metadata": {"id": "hM5NAO7mowoT"}, "id": "hM5NAO7mowoT", "execution_count": null}, {"cell_type": "markdown", "source": ["In the previous sections we have seen the mechanics of creating and using two time-series forecasting models. The univariate model is simpler to create and is simpler to use for forecasting. The multivariate model can give more accurate forecasting. In a real production implementation it would be important to capture the prediction results and compare with the actual outcomes. This would help to decide if it's worth building the multivariate model, fine tune other model parameters - training data period, additional features, effect of holidays and seasonality, etc."], "metadata": {"id": "GysbMt0ho5Ff"}, "id": "GysbMt0ho5Ff", "execution_count": null}, {"cell_type": "markdown", "source": ["Part of the model selection process is model evaluation and forecast evaluation.  "], "metadata": {"id": "Ebv39XrfO6o-"}, "id": "Ebv39XrfO6o-", "execution_count": null}, {"cell_type": "markdown", "source": ["## Model evaluation"], "metadata": {"id": "kMarPZ2DP4qf"}, "id": "kMarPZ2DP4qf", "execution_count": null}, {"cell_type": "code", "source": ["%%bigquery arima_plus_model_evaluation --project {PROJECT_ID}\n", "\n", "SELECT\n", "  *\n", "FROM\n", "  ML.ARIMA_EVALUATE(MODEL multimodal.ridership_arima_plus, STRUCT(FALSE AS show_all_candidate_models))"], "metadata": {"id": "AqfIvpT5Ps4E"}, "id": "AqfIvpT5Ps4E", "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["display_columns_as_rows(arima_plus_model_evaluation)"], "metadata": {"id": "0FoUfb7WUlDO"}, "id": "0FoUfb7WUlDO", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["You can see that there are multiple time series models under the over, one for each bus stop. For details on how to interpret the output of ML.ARIMA_EVALUATE function refer to the [BigQuery documentation](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-arima-evaluate)."], "metadata": {"id": "xcCjLpKHXB7a"}, "id": "xcCjLpKHXB7a", "execution_count": null}, {"cell_type": "markdown", "source": ["## Forecast explanation"], "metadata": {"id": "KNodZZ8IQCiD"}, "id": "KNodZZ8IQCiD", "execution_count": null}, {"cell_type": "markdown", "source": ["To evaluate the forecast, use the same parameters as use for ML.FORECAST function to call ML.EXPLAIN_FORECAST:"], "metadata": {"id": "K2jgJeqZQHJl"}, "id": "K2jgJeqZQHJl", "execution_count": null}, {"cell_type": "code", "source": ["%%bigquery arima_plus_forecast_explanation --project {PROJECT_ID}\n", "\n", "SELECT *\n", " FROM ML.EXPLAIN_FORECAST(\n", "  MODEL multimodal.ridership_arima_plus,\n", "  STRUCT(300 AS horizon, 0.8 AS confidence_level))"], "metadata": {"id": "vUCLXzghQd3A"}, "id": "vUCLXzghQd3A", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["The output of the function contains two types of records - the ones that were used for trainging and the actual forecast.\n", "\n", "Here are a couple of records of historical records:"], "metadata": {"id": "ihstT3O6EM_G"}, "id": "ihstT3O6EM_G", "execution_count": null}, {"cell_type": "code", "source": ["data_to_show = arima_plus_forecast_explanation[\n", "    (arima_plus_forecast_explanation['bus_stop_id'] == 'bus-stop-1') &\n", "    (arima_plus_forecast_explanation['time_series_type'] == 'history')]\n", "\n", "\n", "display_columns_as_rows(data_to_show.head(2))"], "metadata": {"id": "VEMbJ4Q4ROzK"}, "id": "VEMbJ4Q4ROzK", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["And here are some fo the forecast records:"], "metadata": {"id": "8QXl2XjWEsx9"}, "id": "8QXl2XjWEsx9", "execution_count": null}, {"cell_type": "code", "source": ["data_to_show = arima_plus_forecast_explanation[\n", "    (arima_plus_forecast_explanation['bus_stop_id'] == 'bus-stop-1') &\n", "    (arima_plus_forecast_explanation['time_series_type'] == 'forecast')]\n", "\n", "\n", "display_columns_as_rows(data_to_show.head(2))"], "metadata": {"id": "4jzn6HjYExXk"}, "id": "4jzn6HjYExXk", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["For details on how to interpret the output of the function refer to the [BigQuery documentation](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-explain-forecast)."], "metadata": {"id": "tDBHRk4uThp6"}, "id": "tDBHRk4uThp6", "execution_count": null}, {"cell_type": "markdown", "source": ["# Conclusion"], "metadata": {"id": "6LW15mttL7QA"}, "id": "6LW15mttL7QA", "execution_count": null}, {"cell_type": "markdown", "source": ["We showed how you can use two different time-series forecasting models available in BigQuery.\n", "\n", "We also showed how the WeatherNext Graph dataset can be used to get historical and future weather forecasts.\n", "\n", "There are multiple use cases for these time-series forecasts. For example, an AI agent can use the results of ridership forecast as an input to decision on how to perform a task like this: \"In the next week schedule the repair of the bus stop #2 during the least impactful to passengers time\"."], "metadata": {"id": "CcuS8-5QWgPP"}, "id": "CcuS8-5QWgPP", "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.10"}, "colab": {"provenance": [], "name": "lakehouse_part3_time_series_forecasting.ipynb", "toc_visible": true}}, "nbformat": 4, "nbformat_minor": 5}